{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "from pickleshare import PickleShareDB\n",
    "import streamlit as st\n",
    "from streamlit_option_menu import option_menu\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agg_insurance\n",
    "\n",
    "path= \"C:/Users/nkn05/OneDrive/Desktop/Phonepe/pulse/data/aggregated/insurance/country/india/state/\"\n",
    "\n",
    "agg_insur_list= os.listdir(path)\n",
    "\n",
    "columns1= {\"States\":[], \"Years\":[], \"Quarter\":[], \"Insurance_type\":[], \"Transaction_count\":[],\"Transaction_amount\":[] }\n",
    "\n",
    "for state in agg_insur_list:\n",
    "    cur_states =path+state+\"/\"\n",
    "    agg_year_list = os.listdir(cur_states)\n",
    "    \n",
    "    for year in agg_year_list:\n",
    "        cur_years = cur_states+year+\"/\"\n",
    "        agg_file_list = os.listdir(cur_years)\n",
    "\n",
    "        for file in agg_file_list:\n",
    "            cur_files = cur_years+file\n",
    "            data = open(cur_files,\"r\")\n",
    "            A = json.load(data)\n",
    "\n",
    "            for i in A[\"data\"][\"transactionData\"]:\n",
    "                name = i[\"name\"]\n",
    "                count = i[\"paymentInstruments\"][0][\"count\"]\n",
    "                amount = i[\"paymentInstruments\"][0][\"amount\"]\n",
    "                columns1[\"Insurance_type\"].append(name)\n",
    "                columns1[\"Transaction_count\"].append(count)\n",
    "                columns1[\"Transaction_amount\"].append(amount)\n",
    "                columns1[\"States\"].append(state)\n",
    "                columns1[\"Years\"].append(year)\n",
    "                columns1[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "\n",
    "aggre_insurance = pd.DataFrame(columns1)\n",
    "aggre_insurance['Years']=aggre_insurance['Years'].astype(int)\n",
    "\n",
    "aggre_insurance[\"States\"] = aggre_insurance[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "aggre_insurance[\"States\"] = aggre_insurance[\"States\"].str.replace(\"-\",\" \")\n",
    "aggre_insurance[\"States\"] = aggre_insurance[\"States\"].str.title()\n",
    "aggre_insurance['States'] = aggre_insurance['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agg_Trans\n",
    "path1=\"C:/Users/nkn05/OneDrive/Desktop/Phonepe/pulse/data/aggregated/transaction/country/india/state/\"\n",
    "agg_trans_list=os.listdir(path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns2={'States':[],'Years':[],'Quarter':[],'Transaction_type':[],'Transaction_count':[],'Transaction_amount':[]}\n",
    "for state in agg_trans_list:\n",
    "    cur_states=path1+state+\"/\"\n",
    "    agg_year_list=os.listdir(cur_states)\n",
    "\n",
    "    for year in agg_year_list:\n",
    "        cur_year=cur_states+year+'/'\n",
    "        agg_file_list=os.listdir(cur_year)\n",
    "\n",
    "        for file in agg_file_list:\n",
    "            cur_file=cur_year + file\n",
    "            data=open(cur_file,\"r\")\n",
    "        \n",
    "            B=json.load(data)\n",
    "\n",
    "            for i in B['data']['transactionData']:\n",
    "                name=i['name']\n",
    "                count=i['paymentInstruments'][0]['count']\n",
    "                amount=i['paymentInstruments'][0]['amount']\n",
    "                columns2['Transaction_type'].append(name)\n",
    "                columns2['Transaction_count'].append(count)\n",
    "                columns2['Transaction_amount'].append(amount)\n",
    "                columns2['States'].append(state)\n",
    "                columns2['Years'].append(year)\n",
    "                columns2['Quarter'].append(int(file.strip('.json')))\n",
    "\n",
    "\n",
    "agg_transaction=pd.DataFrame(columns2)\n",
    "\n",
    "agg_transaction['Years']=agg_transaction['Years'].astype(int)\n",
    "\n",
    "agg_transaction[\"States\"] = agg_transaction[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "agg_transaction[\"States\"] = agg_transaction[\"States\"].str.replace(\"-\",\" \")\n",
    "agg_transaction[\"States\"] = agg_transaction[\"States\"].str.title()\n",
    "agg_transaction['States'] = agg_transaction['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agg_User\n",
    "\n",
    "path2=\"C:/Users/nkn05/OneDrive/Desktop/Phonepe/pulse/data/aggregated/user/country/india/state/\"\n",
    "agg_user_list=os.listdir(path2)\n",
    "\n",
    "columns3={\"States\":[], \"Years\":[], \"Quarter\":[], \"Brands\":[],\"Transaction_count\":[], \"Percentage\":[]}\n",
    "\n",
    "for state in agg_user_list:\n",
    "    cur_states=path2+state+\"/\"\n",
    "    agg_year_list=os.listdir(cur_states)\n",
    "\n",
    "    for year in agg_year_list:\n",
    "        cur_year=cur_states+year+'/'\n",
    "        agg_file_list=os.listdir(cur_year)\n",
    "\n",
    "        for file in agg_file_list:\n",
    "            cur_file=cur_year + file\n",
    "            data=open(cur_file,\"r\")\n",
    "        \n",
    "            C=json.load(data)\n",
    "\n",
    "            try:\n",
    "\n",
    "                for i in C[\"data\"][\"usersByDevice\"]:\n",
    "                    brand = i[\"brand\"]\n",
    "                    count = i[\"count\"]\n",
    "                    percentage = i[\"percentage\"]\n",
    "                    columns3[\"Brands\"].append(brand)\n",
    "                    columns3[\"Transaction_count\"].append(count)\n",
    "                    columns3[\"Percentage\"].append(percentage)\n",
    "                    columns3[\"States\"].append(state)\n",
    "                    columns3[\"Years\"].append(year)\n",
    "                    columns3[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "            \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "aggre_user = pd.DataFrame(columns3)\n",
    "\n",
    "aggre_user['Years']=aggre_user['Years'].astype(int)\n",
    "\n",
    "aggre_user[\"States\"] = aggre_user[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "aggre_user[\"States\"] = aggre_user[\"States\"].str.replace(\"-\",\" \")\n",
    "aggre_user[\"States\"] = aggre_user[\"States\"].str.title()\n",
    "aggre_user['States'] = aggre_user['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map_insurance\n",
    "\n",
    "path3= \"C:/Users/nkn05/OneDrive/Desktop/Phonepe/pulse/data/map/insurance/hover/country/india/state/\"\n",
    "\n",
    "map_insur_list= os.listdir(path3)\n",
    "\n",
    "columns4= {\"States\":[], \"Years\":[], \"Quarter\":[], \"Districts\":[], \"Transaction_count\":[],\"Transaction_amount\":[] }\n",
    "\n",
    "for state in map_insur_list:\n",
    "    curs_states =path3+state+ \"/\"\n",
    "    map_year_list = os.listdir(curs_states)\n",
    "    \n",
    "    for year in map_year_list:\n",
    "        curs_years = curs_states+year+\"/\"\n",
    "        map_file_list = os.listdir(curs_years)\n",
    "\n",
    "        for file in map_file_list:\n",
    "            curs_files = curs_years+file\n",
    "            data = open(curs_files,\"r\")\n",
    "            E = json.load(data)\n",
    "\n",
    "\n",
    "            for i in E[\"data\"][\"hoverDataList\"]:\n",
    "                name = i[\"name\"]\n",
    "                count = i[\"metric\"][0][\"count\"]\n",
    "                amount = i[\"metric\"][0][\"amount\"]\n",
    "                columns4[\"Districts\"].append(name)\n",
    "                columns4[\"Transaction_count\"].append(count)\n",
    "                columns4[\"Transaction_amount\"].append(amount)\n",
    "                columns4[\"States\"].append(state)\n",
    "                columns4[\"Years\"].append(year)\n",
    "                columns4[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "\n",
    "map_insurance = pd.DataFrame(columns4)\n",
    "\n",
    "map_insurance[\"States\"] = map_insurance[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "map_insurance[\"States\"] = map_insurance[\"States\"].str.replace(\"-\",\" \")\n",
    "map_insurance[\"States\"] = map_insurance[\"States\"].str.title()\n",
    "map_insurance['States'] = map_insurance['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_transaction\n",
    "\n",
    "path4 = \"C:/Users/nkn05/OneDrive/Desktop/Phonepe/pulse/data/map/transaction/hover/country/india/state/\"\n",
    "map_tran_list = os.listdir(path4)\n",
    "\n",
    "columns5 = {\"States\":[], \"Years\":[], \"Quarter\":[],\"District\":[], \"Transaction_count\":[],\"Transaction_amount\":[]}\n",
    "\n",
    "for state in map_tran_list:\n",
    "    cur_states = path3+state+\"/\"\n",
    "    map_year_list = os.listdir(cur_states)\n",
    "    \n",
    "    for year in map_year_list:\n",
    "        cur_years = cur_states+year+\"/\"\n",
    "        map_file_list = os.listdir(cur_years)\n",
    "        \n",
    "        for file in map_file_list:\n",
    "            cur_files = cur_years+file\n",
    "            data = open(cur_files,\"r\")\n",
    "            F = json.load(data)\n",
    "\n",
    "            for i in F['data'][\"hoverDataList\"]:\n",
    "                name = i[\"name\"]\n",
    "                count = i[\"metric\"][0][\"count\"]\n",
    "                amount = i[\"metric\"][0][\"amount\"]\n",
    "                columns5[\"District\"].append(name)\n",
    "                columns5[\"Transaction_count\"].append(count)\n",
    "                columns5[\"Transaction_amount\"].append(amount)\n",
    "                columns5[\"States\"].append(state)\n",
    "                columns5[\"Years\"].append(year)\n",
    "                columns5[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "map_transaction = pd.DataFrame(columns5)\n",
    "\n",
    "map_transaction[\"States\"] = map_transaction[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "map_transaction[\"States\"] = map_transaction[\"States\"].str.replace(\"-\",\" \")\n",
    "map_transaction[\"States\"] = map_transaction[\"States\"].str.title()\n",
    "map_transaction['States'] = map_transaction['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map_user\n",
    "path5 = \"C:/Users/nkn05/OneDrive/Desktop/Phonepe/pulse/data/map/user/hover/country/india/state/\"\n",
    "map_user_list = os.listdir(path5)\n",
    "\n",
    "columns6 = {\"States\":[], \"Years\":[], \"Quarter\":[], \"Districts\":[], \"RegisteredUser\":[], \"AppOpens\":[]}\n",
    "\n",
    "for state in map_user_list:\n",
    "    cur_states = path5+state+\"/\"\n",
    "    map_year_list = os.listdir(cur_states)\n",
    "    \n",
    "    for year in map_year_list:\n",
    "        cur_years = cur_states+year+\"/\"\n",
    "        map_file_list = os.listdir(cur_years)\n",
    "        \n",
    "        for file in map_file_list:\n",
    "            cur_files = cur_years+file\n",
    "            data = open(cur_files,\"r\")\n",
    "            G = json.load(data)\n",
    "\n",
    "            for i in G[\"data\"][\"hoverData\"].items():\n",
    "                district = i[0]\n",
    "                registereduser = i[1][\"registeredUsers\"]\n",
    "                appopens = i[1][\"appOpens\"]\n",
    "                columns6[\"Districts\"].append(district)\n",
    "                columns6[\"RegisteredUser\"].append(registereduser)\n",
    "                columns6[\"AppOpens\"].append(appopens)\n",
    "                columns6[\"States\"].append(state)\n",
    "                columns6[\"Years\"].append(year)\n",
    "                columns6[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "map_user = pd.DataFrame(columns6)\n",
    "\n",
    "map_user[\"States\"] = map_user[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "map_user[\"States\"] = map_user[\"States\"].str.replace(\"-\",\" \")\n",
    "map_user[\"States\"] = map_user[\"States\"].str.title()\n",
    "map_user['States'] = map_user['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_insurance\n",
    "path6 = \"C:/Users/nkn05/OneDrive/Desktop/Phonepe/pulse/data/top/insurance/country/india/state/\"\n",
    "\n",
    "top_insur_list = os.listdir(path6)\n",
    "\n",
    "columns7 = {\"States\":[], \"Years\":[], \"Quarter\":[], \"Pincodes\":[], \"Transaction_count\":[], \"Transaction_amount\":[]}\n",
    "\n",
    "for state in top_insur_list:\n",
    "    cur_states = path6+state+\"/\"\n",
    "    top_year_list = os.listdir(cur_states)\n",
    "\n",
    "    for year in top_year_list:\n",
    "        cur_years = cur_states+year+\"/\"\n",
    "        top_file_list = os.listdir(cur_years)\n",
    "\n",
    "        for file in top_file_list:\n",
    "            cur_files = cur_years+file\n",
    "            data = open(cur_files,\"r\")\n",
    "            H = json.load(data)\n",
    "\n",
    "            for i in H[\"data\"][\"districts\"]:\n",
    "                entityName = i[\"entityName\"]\n",
    "                count = i[\"metric\"][\"count\"]\n",
    "                amount = i[\"metric\"][\"amount\"]\n",
    "                columns7[\"Pincodes\"].append(entityName)\n",
    "                columns7[\"Transaction_count\"].append(count)\n",
    "                columns7[\"Transaction_amount\"].append(amount)\n",
    "                columns7[\"States\"].append(state)\n",
    "                columns7[\"Years\"].append(year)\n",
    "                columns7[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "top_insur = pd.DataFrame(columns7)\n",
    "\n",
    "\n",
    "top_insur[\"States\"] = top_insur[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "top_insur[\"States\"] = top_insur[\"States\"].str.replace(\"-\",\" \")\n",
    "top_insur[\"States\"] = top_insur[\"States\"].str.title()\n",
    "top_insur['States'] = top_insur['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_transaction\n",
    "\n",
    "path7=\"C:/Users/nkn05/OneDrive/Desktop/Phonepe/pulse/data/top/transaction/country/india/state/\"\n",
    "\n",
    "top_tran_list=os.listdir(path7)\n",
    "\n",
    "columns8 = {\"States\":[], \"Years\":[], \"Quarter\":[], \"Pincodes\":[], \"Transaction_count\":[], \"Transaction_amount\":[]}\n",
    "\n",
    "for state in top_tran_list:\n",
    "    cur_states=path7 + state + \"/\"\n",
    "    top_year_list=os.listdir(cur_states)\n",
    "\n",
    "    for year in top_year_list:\n",
    "        cur_year= cur_states + year + \"/\"\n",
    "        top_file_list=os.listdir(cur_year)\n",
    "\n",
    "        for file in top_file_list:\n",
    "            cur_file=cur_year+file\n",
    "            data=open(cur_file,'r')\n",
    "            I=json.load(data)\n",
    "\n",
    "            for i in I[\"data\"][\"districts\"]:\n",
    "                entityName = i[\"entityName\"]\n",
    "                count = i[\"metric\"][\"count\"]\n",
    "                amount = i[\"metric\"][\"amount\"]\n",
    "                columns8[\"Pincodes\"].append(entityName)\n",
    "                columns8[\"Transaction_count\"].append(count)\n",
    "                columns8[\"Transaction_amount\"].append(amount)\n",
    "                columns8[\"States\"].append(state)\n",
    "                columns8[\"Years\"].append(year)\n",
    "                columns8[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "top_transaction=pd.DataFrame(columns8)\n",
    "\n",
    "\n",
    "top_transaction[\"States\"] = top_transaction[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "top_transaction[\"States\"] = top_transaction[\"States\"].str.replace(\"-\",\" \")\n",
    "top_transaction[\"States\"] = top_transaction[\"States\"].str.title()\n",
    "top_transaction['States'] = top_transaction['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_user\n",
    "\n",
    "path8='C:/Users/nkn05/OneDrive/Desktop/Phonepe/pulse/data/top/user/country/india/state/'\n",
    "\n",
    "top_user_list=os.listdir(path8)\n",
    "\n",
    "columns9 = {\"States\":[], \"Years\":[], \"Quarter\":[],\"Pincodes\":[], \"RegisteredUser\":[]}\n",
    "\n",
    "for state in top_user_list:\n",
    "    cur_states=path8 + state + '/'\n",
    "    top_year_list=os.listdir(cur_states)\n",
    "\n",
    "    for year in top_year_list:\n",
    "        cur_year= cur_states + year + \"/\"\n",
    "        top_file_list=os.listdir(cur_year)\n",
    "\n",
    "        for file in top_file_list:\n",
    "            cur_file=cur_year+file\n",
    "            data=open(cur_file,'r')\n",
    "            J=json.load(data)\n",
    "\n",
    "            for i in J[\"data\"][\"districts\"]:\n",
    "                Districts=i['name']\n",
    "                RegisteredUser=i['registeredUsers']\n",
    "                columns9['Pincodes'].append(Districts)\n",
    "                columns9[\"RegisteredUser\"].append(RegisteredUser)\n",
    "                columns9['States'].append(state)\n",
    "                columns9['Years'].append(year)\n",
    "                columns9['Quarter'].append(int(file.strip(\".json\")))\n",
    "\n",
    "top_user=pd.DataFrame(columns9)\n",
    "\n",
    "top_user[\"States\"] = top_user[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "top_user[\"States\"] = top_user[\"States\"].str.replace(\"-\",\" \")\n",
    "top_user[\"States\"] = top_user[\"States\"].str.title()\n",
    "top_user['States'] = top_user['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Table Creation\n",
    "#mysql connection\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "    username='root',\n",
    "    host=\"localhost\",\n",
    "    password=\"Gopi2708\",\n",
    "    database='phonepe')\n",
    "\n",
    "cursor = mydb.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregated insurance table\n",
    "create_query1= '''CREATE TABLE if not exists aggregated_insurance (States varchar(50),\n",
    "                                                                      Years int,\n",
    "                                                                      Quarter int,\n",
    "                                                                      Insurance_type varchar(50),\n",
    "                                                                      Transaction_count bigint,\n",
    "                                                                      Transaction_amount bigint\n",
    "                                                                      )'''\n",
    "cursor.execute(create_query1)\n",
    "mydb.commit()\n",
    "\n",
    "\n",
    "insert_query1 = '''INSERT INTO aggregated_insurance (States, Years, Quarter, Insurance_type, Transaction_count, Transaction_amount)\n",
    "                                                        values(%s,%s,%s,%s,%s,%s)'''\n",
    "\n",
    "data=aggre_insurance.values.tolist()\n",
    "\n",
    "cursor.executemany(insert_query1,data)\n",
    "\n",
    "mydb.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregated transaction table\n",
    "create_query2 = '''CREATE TABLE if not exists aggregated_transaction (States varchar(50),\n",
    "                                                                      Years int,\n",
    "                                                                      Quarter int,\n",
    "                                                                      Transaction_type varchar(50),\n",
    "                                                                      Transaction_count bigint,\n",
    "                                                                      Transaction_amount bigint\n",
    "                                                                      )'''\n",
    "cursor.execute(create_query2)\n",
    "mydb.commit()\n",
    "\n",
    "insert_query2 = '''INSERT INTO aggregated_transaction (States, Years, Quarter, Transaction_type, Transaction_count, Transaction_amount)\n",
    "                                                    values(%s,%s,%s,%s,%s,%s)'''\n",
    "data=agg_transaction.values.tolist()\n",
    "\n",
    "cursor.executemany(insert_query2,data)\n",
    "mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregated_user_table\n",
    "create_query3 = '''CREATE TABLE if not exists aggregated_user (States varchar(50),\n",
    "                                                                Years int,\n",
    "                                                                Quarter int,\n",
    "                                                                Brands varchar(50),\n",
    "                                                                Transaction_count bigint,\n",
    "                                                                Percentage float)'''\n",
    "cursor.execute(create_query3)\n",
    "mydb.commit()\n",
    "\n",
    "\n",
    "insert_query3 = '''INSERT INTO aggregated_user (States, Years, Quarter, Brands, Transaction_count, Percentage)\n",
    "                                                    values(%s,%s,%s,%s,%s,%s)'''\n",
    "data=aggre_user.values.tolist()\n",
    "cursor.executemany(insert_query3,data)\n",
    "mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map_insurance_table\n",
    "create_query4 = '''CREATE TABLE if not exists map_insurance (States varchar(50),\n",
    "                                                                Years int,\n",
    "                                                                Quarter int,\n",
    "                                                                District varchar(50),\n",
    "                                                                Transaction_count bigint,\n",
    "                                                                Transaction_amount float)'''\n",
    "cursor.execute(create_query4)\n",
    "mydb.commit()\n",
    "\n",
    "\n",
    "insert_query4 = '''\n",
    "                INSERT INTO map_insurance (States, Years, Quarter, District, Transaction_count, Transaction_amount)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s) '''\n",
    "\n",
    "data=map_insurance.values.tolist()\n",
    "            \n",
    "cursor.executemany(insert_query4,data)\n",
    "mydb.commit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#map_transaction_table\n",
    "create_query5 = '''CREATE TABLE if not exists map_transaction (States varchar(50),\n",
    "                                                                Years int,\n",
    "                                                                Quarter int,\n",
    "                                                                District varchar(50),\n",
    "                                                                Transaction_count bigint,\n",
    "                                                                Transaction_amount float)'''\n",
    "cursor.execute(create_query5)\n",
    "mydb.commit()\n",
    "\n",
    "\n",
    "insert_query5 = '''\n",
    "                INSERT INTO map_Transaction (States, Years, Quarter, District, Transaction_count, Transaction_amount)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s)'''\n",
    "\n",
    "data=map_transaction.values.tolist()\n",
    "            \n",
    "cursor.executemany(insert_query5,data)\n",
    "mydb.commit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map_user_table\n",
    "create_query6 = '''CREATE TABLE if not exists map_user (States varchar(50),\n",
    "                                                        Years int,\n",
    "                                                        Quarter int,\n",
    "                                                        Districts varchar(50),\n",
    "                                                        RegisteredUser bigint,\n",
    "                                                        AppOpens bigint)'''\n",
    "cursor.execute(create_query6)\n",
    "mydb.commit()\n",
    "\n",
    "insert_query6 = '''INSERT INTO map_user (States, Years, Quarter, Districts, RegisteredUser, AppOpens)\n",
    "                    values(%s,%s,%s,%s,%s,%s)'''\n",
    "\n",
    "data=map_user.values.tolist()\n",
    "            \n",
    "cursor.executemany(insert_query6,data)\n",
    "mydb.commit() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_insurance_table\n",
    "create_query7 = '''CREATE TABLE if not exists top_insurance (States varchar(50),\n",
    "                                                                Years int,\n",
    "                                                                Quarter int,\n",
    "                                                                pincodes varchar(50),\n",
    "                                                                Transaction_count bigint,\n",
    "                                                                Transaction_amount bigint)'''\n",
    "cursor.execute(create_query7)\n",
    "mydb.commit()\n",
    "\n",
    "\n",
    "insert_query7 = '''INSERT INTO top_insurance (States, Years, Quarter, pincodes, Transaction_count, Transaction_amount)\n",
    "                                                    values(%s,%s,%s,%s,%s,%s)'''\n",
    "    \n",
    "data=top_insur.values.tolist()\n",
    "            \n",
    "cursor.executemany(insert_query7,data)\n",
    "mydb.commit() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_transaction_table\n",
    "create_query8 = '''CREATE TABLE if not exists top_transaction (States varchar(50),\n",
    "                                                                Years int,\n",
    "                                                                Quarter int,\n",
    "                                                                pincodes varchar(50),\n",
    "                                                                Transaction_count bigint,\n",
    "                                                                Transaction_amount bigint)'''\n",
    "cursor.execute(create_query8)\n",
    "mydb.commit()\n",
    "\n",
    "insert_query8 = '''INSERT INTO top_transaction (States, Years, Quarter, pincodes, Transaction_count, Transaction_amount)\n",
    "                                                    values(%s,%s,%s,%s,%s,%s)'''\n",
    "data = [tuple(row) for row in top_transaction.values]\n",
    "cursor.executemany(insert_query8,data)\n",
    "mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#top_user_table\n",
    "create_query9 = '''CREATE TABLE if not exists top_user (States varchar(50),\n",
    "                                                        Years int,\n",
    "                                                        Quarter int,\n",
    "                                                        pincodes varchar(50),\n",
    "                                                        RegisteredUser bigint\n",
    "                                                        )'''\n",
    "cursor.execute(create_query9)\n",
    "mydb.commit()\n",
    "\n",
    "\n",
    "insert_query9 = '''INSERT INTO top_user (States, Years, Quarter, pincodes, RegisteredUser)\n",
    "                                            values(%s,%s,%s,%s,%s)'''\n",
    "\n",
    "# Convert DataFrame to list of tuples\n",
    "data = [tuple(row) for row in top_user.values]\n",
    "\n",
    "cursor.executemany(insert_query9,data)\n",
    "mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the root directory for the PickleShare database\n",
    "root_directory = 'c:/Users/nkn05/OneDrive/Desktop/Phonepe/pulse/default_db/'\n",
    "\n",
    "# Create or open a PickleShare database with the specified root directory\n",
    "db = PickleShareDB(root=root_directory)\n",
    "\n",
    "#stored_aggre_insurance\n",
    "\n",
    "db['aggre_insurance']=aggre_insurance\n",
    "\n",
    "#stored_agg_transaction\n",
    "db['agg_transaction']=agg_transaction\n",
    "\n",
    "#stored_agg_user\n",
    "db['aggre_user']=aggre_user\n",
    "\n",
    "#stored_map_insurance\n",
    "db['map_insurance']=map_insurance\n",
    "\n",
    "#stored_map_transaction\n",
    "db['map_transaction']=map_transaction\n",
    "\n",
    "#stored_map_user\n",
    "db['map_user']=map_user\n",
    "\n",
    "#stored_top_insurance\n",
    "db['top_insur']=top_insur\n",
    "\n",
    "#stored_top_transaction\n",
    "db['top_transaction']=top_transaction\n",
    "\n",
    "#stored_top_user\n",
    "db['top_user']=top_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
